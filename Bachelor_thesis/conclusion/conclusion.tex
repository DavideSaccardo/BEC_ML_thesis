We started this work with two main goals: the first was to verify whether it was possible to apply Machine Learning methods to compute the ground state energy of a BEC and secondly whether it was possible to learn something more about the Restricted Boltzmann Machine itself. We can safely state that we were able to accomplish both goals. 

We were able to write an object-oriented code in C++ which computes the energy of a Bose-Einstein condensate through Variational Monte Carlo methods with a trial wave-function constructed with the RBM. The algorithms used to compute energy, errors and to sample were discussed. The Importance Sampling Metropolis-Hastings algorithm was found to produce smaller errors than the Brute Force Metropolis one. The code was benchmarked with the case of non-interacting particles in a spherical harmonic potential with satisfactory results. On the other hand, the test with non-interacting particles in an elliptical harmonic potential was a failure. We were able to fix this problem by biasing the z direction with ad hoc parameters found through a trial and error procedure. Nevertheless we have learnt that the Restricted Boltzmann Machine faces serious problems when it has to a learn an elliptical symmetry. \\
As regards interacting particles in an elliptical harmonic potential, we computed the local energy per particle $E_L/N_p$ for $N_p=10,20,30,40,50,60,70,80,90,100$. We compared the results with the ones obtained from GP equation (eq. (\ref{GP})) in \cite{DalfString}. Even though the trend was similar to GP, in general our results seemed to underestimate GP for $N_p>20$. We argue that our algorithms might be effected by a systematic error that we are not able to evaluate with our statistical analysis. Therefore, further analysis are needed. Nevertheless, we note that this problem could be fixed by increasing the number of hidden nodes at the cost of increasing abruptly the computational time. Anyway, we should take into account that that our limit with this current setup is about N$=300$ visible nodes and M$=60$ invisible nodes. As we noted this leads to 18360 total parameters to adjust at each interaction. \\
We report the result with $N_p=100$:
\begin{equation*}
	\frac{E_L}{N_p}=\SI{2.63\pm 0.02}{}\ \hbar\omega_{ho}
\end{equation*} 
which can be directly compared with $E_L/N_p=2.66\  \hbar\omega_{ho}$ obtained from GP in \cite{DalfString}. The agreement is really good.

In \cite{carleoSolvingQuantumManybody2017} Carleo and Troviks were able to apply ML to a chain of $80$ spins and a $10\times 10$ lattice. Therefore, having been able to apply ML to $100$ interacting particles in an elliptical harmonic potential in 3D could be considered a satisfactory result.  


Nevertheless the are several improvements that we can implement to our code. First of all, we can find a way to parallelize it in order to gather more data and to lower the error. \\
Instead of fixing the elliptical symmetry with two ad hoc parameters such as $\xi_1$ and $\xi_2$, we could insert two variational parameters in those positions initialized with the values of $\xi_1$ and $\xi_2$ which we have found. In this way, the RBM should be able to represent the elliptical symmetry with more precision. \\
Another interesting test would be to modify RBM or to implement some other machine in order to check whether we are able to increase the number of particles as well as the number of hidden nodes without breaking the stability. \\
Overall we should speed up the code. This would allow us to increase the number of SGD cycles and, in particular, of hidden nodes without increasing dramatically the computational time.\\
Other limitations regard the Stochastic Gradient Descent method such as the oscillation of the energy in the elliptical case and the constraint to set a fixed learning rate. In particular, the second leaded to divergent energy if $\eta$ had been set too high, or slow convergence if it had been too small. Therefore, firstly, we should update our algorithm by adding the so-called Momentum method which accelerates the SGD in the relevant direction. By consequence it lowers the oscillations. This is straightforward to implement. Then, we should introduce a dynamic learning rate which adapts itself at each cycle. Examples are countless: RMSProp (Root Mean Square Propagator), Adam (Adaptive Moment Estimation), ADAdelta, etc. They are all quite similar. Hence the task would be to understand which one is the best for our case and then to implement it. 



