In recent times Machine Learning (ML) methods using neural networks (NN) has become increasingly better at simulating quantum systems. In \cite{carleoSolvingQuantumManybody2017} Carleo and Troyer discuss the impressive potential of ML and NN methods over traditional methods.  In their article, they apply the so-called Binary-Binary Restricted Boltzmann Machine (RBM) to the quantum mechanical spin lattice systems of the Ising model and Heisenberg model, with
encouraging results. \\
In general, the topic of Machine Learning and Neural Network is gaining a lot of success: people are using such algorithms in different contexts such as speech (e.g. Google Translate) or objects (e.g. plants, handwritten numbers, etc.) recognition. Such applications are interesting but they are not that important for physics. Nowadays research is more focused on using ML to understand which are the paths connecting, for example, two states (configurations) which are more important (biased). Usually each path would be considered, this could lead to an impossible problem to deal with. However, by knowing which are the more important paths, with a good approximation, it could be possible to exclude the less important ones. A simplification of the problem is a consequence. Examples could be provided by excited states in nuclear physics (carried out by coupled-cluster methods) or lattice QCD.

In this thesis we will test the applicability of the RBM to the Bose-Einstein condensate (BEC) to compute its ground state energy. The ground state energy of a BEC is a well known result \cite{DalfString}. Therefore our aim is not to introduce something new in that direction but to check whether the ML approach could be used also here and whether we can learn something more about ML itself. The basic idea is to use a NN of visible and hidden nodes to represent a system wave-function $\Psi$. The weights of these nodes act as variational parameters leading to the convenient use of the variational method to approximate the ground state. The energy of $\Psi$ is calculated and the (Stochastic) Gradient Descent (SGD) method is applied to find the set of parameters that minimize the energy function. In particular we use a Gaussian-Binary RBM as choice of NN to represent $\Psi$.

First of all, we study one and two non-interacting bosons in a 1D,2D and 3D spherical harmonic potential. We consider such a small number of particles just for the sake of computational speed. Anyway, this case is particularly useful: the system becomes a harmonic oscillator and thus we have analytical solutions that we can use to benchmark our code. Then, we study the same system in a 3D elliptical harmonic potential. We look for possible changes in the system due to the different potential's symmetry adopted. Finally we study the case of interacting bosons in a 3D elliptical harmonic potential. We skip the 2D case since for the three dimensional one we have results to benchmark ours. The interaction between bosons is modeled with a hard-core potential.

The ground state energy is computed through Variational Monte Carlo (VMC) methods, a class of iterative technique employing the repeated use of random sampling and statistical analysis to solve mathematical problems. The goal is to reproduce a probability distribution through the generation of samples. As they are produced, their values follow more and more precisely the desired distribution. At each interaction, the program choose a candidate from the class of samples based on the current sample (even though improperly, we could also say that the program makes a choice). Then, this candidate is either accepted or rejected with a certain probability. Two aspects are particularly important (strongly connected with each other): the first is how samples are generated (i.e. a sampling rule) and the second is the so-called accept-reject rule. The computational algorithms which describe the accept-reject rule are the Metropolis algorithms. Hence, when a choice of the sampling rule is made, a choice of the accept-reject rule follows and thus a choice of the Metropolis algorithm used. In this paper, we consider two possibilities: a Brute-Force way of generating a sample which leads to the so-called Metropolis algorithm (in the following, we will refer to this procedure as Brute-Force Metropolis algorithm, BFM) and the Importance Sampling way of generating samples which leads to the Metropolis-Hastings algorithm for accepting-rejecting moves (in the following, Importance-Sampling Metropolis-Hastings algorithm, ISMH). In BFM the sampling rule is independent on the trial wave-function and thus it is not really efficient. ISMH is a much better alternative since it proposes moves biased by the trial wave-function that are more likely to be accepted.  Overall the system becomes much better at reproducing the probability distribution.\\
%The basic difference between a normal VMC calculation and our code is related to the trial wave-function as well as to the variation of the variaitonal parameter. 

The results are presented with an appropriate statistical error computed through blocking method which takes into account correlations between data.

The code is object oriented in order to achieve the best flexibility possible. In principle it should be straightforward to (let us say) change the initial configurations of particles, to study systems of fermions or to change the potential.

\section{Bose-Einstein condensate}
A Bose-Einstein condensate is a state of matter in which dilute gases of bosons undergo a phase transition when they are cooled to low temperature ($T\rightarrow 0\ \si{\kelvin}$). As a result the majority of bosons condense into the system ground state (Bose-Einstein condensation, BEC). This gives rise to new quantum phenomena such as superfluidity and phase coherence \cite{Stringari}. 

The concept was proposed for the first time by A. Einstein in 1925 who followed the work of the Indian physicist S. N. Bose (1924) on the statistics of photons and applied it to a gas of non-interacting, massive bosons. However the prediction remained without any practical meaning until the 1938, when F. London realized that BEC could be responsible for the superfluidity in $^4$He. Since the interaction between  atoms in helium is strong \cite{pethick_smith_2008}, it is difficult to measure effectively the number of particles in the condensate. Therefore, research focused on weakly-interacting Bose gases with a higher condensate fraction such as alkali atoms. They were eventually achieved in 1995 by the teams of Cornell and Wieman at Boulder with $^{87}$Rb and of Ketterle at MIT with $^{23}$Na cooled down to temperature of the order of $100\ \si{\nano\kelvin}$ through laser cooling and evaporative cooling in magneto-optical traps. For this discovery, they share the Nobel prize in 2001. 

%Boseâ€“EinsteinCondensationinDiluteGases C. J. Pethick Nordita H. Smith University of Copenhage

%dalfovo article
Since these experiments involve the use of traps, the gases are naturally nonuniform. Moreover, as said above, gases are considered to be dilute which means that the average distance between atoms is much larger than the range of the inter-atomic interaction. Therefore the reference equation is the Gross-Pitaevskii (GP) equation:
\beq
\label{GP}
i\hbar\frac{\partial \Psi (\mathbf{r},t)}{\partial t}=\bigg(-\frac{\hbar^2}{2m}\nabla^2+V(\mathbf{r})+g|\Psi(\mathbf{r},t)|^2\bigg)\Psi(\mathbf{r},t)
\eeq
%\CIT %stringar
where $i=\sqrt{-1}, \hbar$ is the reduced Planck constant, $t$ is time, $\Psi$ is the condensate wave-function, $\mathbf{r}$ represents the position of bosons and $V$ is the external potential which confines the bosons. The quantity $g$ is the coupling constant 
\begin{equation*}
	g=\frac{4\pi\hbar^2a}{m}
\end{equation*}
where $a$ is the s-wave scattering length. GP equation describes inhomogeneous dilute gases such as alkali atoms in magneto-optics trap, its solution will be used to benchmark our results.

In this paper, we compute the ground-state energy of the Bose-Einstein gas and we compare the results with the ones found in literature \cite{DalfString}, where the approach used was steepest descent to minimize the energy functional which describes the ground-state energy in the Gross-Pitaevskii framework. There the physics is dominated by two-body collisions and it can be described through s-wave scattering length $a$. The condition of diluteness is given by the parameter $na^3$, where $n$ is the density of the system. When low values of this parameter are considered the Gross-Pitaevskii theory works very well. However, in some experiments the parameter may exceed the such values. In these cases it may be important to study the problem with a many-body approach. In literature many papers are found of Monte Carlo calculations where a broad range of densities is studied by going beyond the GP equation. For example, in \cite{vmcarticle}, Dubois e Glyde use Variational Monte Carlo (VMC) methods to study the Bose gas from dilute to liquid $^4$He densities. Basically the same range is considered by Giorgini et al. in \cite{Giorgini}, where, conversely, the Diffusion Monte Carlo (DMC) approach is performed, and in Gr\"{u}ter et al. \cite{Gruter}, where the path-integral Monte Carlo is chosen. \\
In this thesis, we use ML and we compare the results with GP equation since we consider a diluite system. Nevertheless, out of the diluite range, we note that ML results should be compared to the Monte Carlo ones which we have briefly mentioned above. 


%Monte Carlo methods with their several variants (diffusion VMC, coupled-cluster, etc) have been use extensively since their development by Ulam in the $1940s-1950s$ to study many-body problem. Our first procedure is basically the quantum mechanics' variational method applied through a Monte Carlo evaluation with a given trial wave-function (\CIT). The variational method allows us to find the an upper limit to the ground state energy which depends on a variational parameter. Therefore the variational parameter $\alpha$ which minimizes the energy is the one that will give the best estimate for the ground state. The gradient descent method is applied to find the optimal $\alpha$. %for both interacting and non case. The non-interacting case is used to prove the efficiency of the method since the best variational parameter can be easily computed.



%In both situations 
 

%\section{Structure of the Thesis}
%\cref{part:intro}
%The Thesis is organized in three sections. In the first one the general system is discussed. Then 